#!/bin/bash
# Copyright 2022 SuperDARN Canada, University of Saskatchewan
# Author: Theodore Kolkman
# Based on auto_borealis_share written by Kevin Krieger
#
# This script distributes borealis rawacf dmap (bz2) and array (HDF5) data to the following 
# organizations/locations:
#   Backs up dmap and array data to sdc-nas0 on campus
#   Verifies correctness of dmap files by reading them with pyDARNio
#   Stages dmap and array data for the SuperDARN mirror on Fir.alliancecan.ca
#   Stages dmap data for sending to British Antarctic Survey (BAS) and Virginia Tech (VT) 
#   Moves any non-standard experiments to a separate special experiments directory
#
# This script performs the following checks before distributing files:
#   - dmap files are unzipped
#   - dmap files are read into pyDARNio via the test_dmap_integrity script. If the file can be 
#     successfully read into pyDARNio, then there is high confidence in the files integrity.
#   - hdf5 array files are tested using h5stat
# If a file fails any of these tests, they are moved to a separate directory for future examination.
# If any dmap files fail a test, the corresponsing array file is also moved to the separate
# directory.
#
# Dependencies:
#   - hdf5 (zypper in hdf5)
#	- ssh link established between sdc-serv and TELEMETRY computers
#
# Usage: ./distribute_borealis_data RADAR_ID
# Parameter RADAR_ID: [sas, pgr, rkn, inv, cly]
#
# This script should be run on sdc-serv.usask.ca via an inotify daemon triggering when the previous
# data flow script finishes. To ensure only one instance runs for each site, use `flock` within the
# inotify daemon code

###################################################################################################

source "${HOME}/data_flow/config.sh"  # Load common data flow variables
source "${HOME}/data_flow/library/data_flow_functions.sh"  # Load in functions
source "${HOME}/pydarnio-env/bin/activate"  # Load in pyDARNio

###################################################################################################

readonly RADAR_ID=$1

if [[ $# -ne 1 ]]; then
    printf "Usage: ./distribute_borealis_data RADAR_ID\n"
    exit 1
fi

if [[ ! " ${VALID_IDS[*]} " =~ " ${RADAR_ID} " ]]; then
    printf "\"$RADAR_ID\" is not a valid radar ID\n"
    exit 1
fi

# Define directories
readonly SOURCE="/sddata/${RADAR_ID}_data"                  # Located on sdc-nas0
readonly NAS_DIR="/data/borealis_site_data"                 # Located on sdc-nas0
readonly MIRROR_STAGING_DIR="/data/holding/globus"          # Located on sdc-nas0
readonly BAS_STAGING_DIR="/home/bas/outgoing/${RADAR_ID}"   # Located locally on sdc-serv
readonly VT_STAGING_DIR="/home/vtsd/outgoing/${RADAR_ID}"   # Located locally on sdc-serv
readonly PROBLEM_FILES_DEST="/sddata/conversion_failure"    # Located on sdc-nas0
readonly SPECIAL_EXPERIMENTS="/sddata/special_experiments"  # Located on sdc-nas0

# Data group for outgoing files
readonly DATA_GROUP="sddata"

# Create log file. New file created daily
readonly LOGGING_DIR="${HOME}/logs/distribute_borealis_data/$(date +%Y/%m)"
mkdir --parents $LOGGING_DIR
readonly LOGFILE="${LOGGING_DIR}/${RADAR_ID}.$(date +%Y%m%d).distribute_borealis_data.log"
readonly  SUMMARY_DIR="${HOME}/logs/distribute_borealis_data/summary/$(date +%Y/%m)"
mkdir --parents $SUMMARY_DIR
readonly SUMMARY_FILE="${SUMMARY_DIR}/${RADAR_ID}.$(date -u +%Y%m%d).distribute_borealis_data_summary.log"

# Telemetry directory for this script and site
readonly TELEMETRY_SCRIPT_DIR="${TELEMETRY_DIR}/${RADAR_ID}/distribute_borealis_data"

###################################################################################################

exec &>> $LOGFILE # Redirect STDOUT and STDERR to $LOGFILE

printf "################################################################################\n\n" | tee --append $SUMMARY_FILE

printf "Executing $(basename "$0") on $(hostname) for ${RADAR_ID}\n" | tee --append $SUMMARY_FILE
date --utc "+%Y%m%d %H:%M:%S UTC" | tee --append $SUMMARY_FILE

# Get status info on data_flow and pyDARNio repos
printf "data_flow: $(git -C ${HOME}/data_flow status | grep "On branch"), last commit: \
		$(git -C ${HOME}/data_flow log -1 --format="%h %cd" --date=iso)\n" | tee --append $SUMMARY_FILE
printf "pyDARNio: $(git -C ${HOME}/pyDARNio status | grep "On branch"), last commit: \
		$(git -C ${HOME}/pyDARNio log -1 --format="%h %cd" --date=iso)\n" | tee --append $SUMMARY_FILE

printf "Distributing from: $SOURCE\n" | tee --append $SUMMARY_FILE
printf "Distributing to: \n\
        \tNAS: $NAS_DIR\n\
        \tMirror: $MIRROR_STAGING_DIR\n\
        \tInstitutions: $BAS_STAGING_DIR\t$VT_STAGING_DIR\n\n" | tee --append $SUMMARY_FILE


# Distribute DMAP files
dmap_files=$(find ${SOURCE} -maxdepth 1 -name "*rawacf.bz2")

if [[ -n $dmap_files ]]; then
    printf "Distributing the following dmap files:\n" 
    printf '%s\n' "${dmap_files[@]}"
else
    printf "No dmap files found to be distributed.\n" | tee --append $SUMMARY_FILE
fi

# Iterate over all dmap files to be transferred. If any dmap files fail conversion checks, both the 
# dmap and corresponding borealis file are moved to a separate directory for further inspection.
for file in $dmap_files; do
    chmod --verbose 664 $file   # Change file permissions to -rw-rw-r--
    borealis_file=$(get_borealis_name $file)  # HDF5 file corresponding to the current dmap file
    printf "\n"
    
    # Test that file can be unzipped
    printf "bzip2 --test $(basename $file)\n"
    bzip2 --test $file
    if [[ $? -eq 2 ]]; then
        printf "DMAP file failed bzip2 test: ${file}\n" | tee --append $SUMMARY_FILE
        mv --verbose $file $PROBLEM_FILES_DEST
        mv --verbose $borealis_file $PROBLEM_FILES_DEST
        continue    # Skip to next dmap file
    fi

    printf "python3 test_dmap_integrity.py $(basename ${file})\n"
    file_cpid=$(python3 "${HOME}/data_flow/campus/test_dmap_integrity.py" $file)

    if [[ -z "$file_cpid" ]]; then  # If no CPID is returned, the file failed to open
        printf "DMAP integrity test failed: ${file}\n" | tee --append $SUMMARY_FILE
        printf "Not distributing ${file}\n"
        mv --verbose $file $PROBLEM_FILES_DEST
        mv --verbose $borealis_file $PROBLEM_FILES_DEST
        continue    # Skip to next file in $dmap_files
    fi

    # Check if experiment is one of the common experiments distributed to the SuperDARN community
    if [[ ! " ${DISTRIBUTED_CPIDS[*]} " =~ " $file_cpid " ]]; then
        # If not, it must be a special experiment, and should be moved accordingly
        printf "File with CPID $file_cpid will not be distributed: ${file}\n" | tee --append $SUMMARY_FILE
        printf "Moving to ${SPECIAL_EXPERIMENTS}\n"

        # Move file to special_experiment directory so it isn't distributed
        year=$(echo ${file_name} | cut --characters 1-4)
        month=$(echo ${file_name} | cut --characters 5-6)
        special_dir="${SPECIAL_EXPERIMENTS}/${RADAR_ID}/${year}/${month}/"
        mkdir --parents $special_dir
        mv --verbose $file $special_dir
        continue
    fi

    printf "Distributing ${file}\n"
    file_name=$(basename $file)

    # Flag will be > 0 if any transfers fail since verify_transfer returns 1 for failed transfer
    transfer_flag=0

    chgrp --verbose $DATA_GROUP $file

    # Place file in vtsd outgoing
    cp --preserve --verbose $file "${VT_STAGING_DIR}/${file_name}" 
    verify_transfer $file "${VT_STAGING_DIR}/${file_name}" 
    return_value=$?
    transfer_flag=$(($transfer_flag + $return_value))

    # Place file in BAS outgoing
    cp --preserve --verbose $file "${BAS_STAGING_DIR}/${file_name}"
    verify_transfer $file "${BAS_STAGING_DIR}/${file_name}"
    return_value=$?
    transfer_flag=$(($transfer_flag + $return_value))

    # Copy for staging to the data mirror on Fir
    cp --preserve --verbose $file "${MIRROR_STAGING_DIR}/${file_name}"
    verify_transfer $file "${MIRROR_STAGING_DIR}/${file_name}"
    return_value=$?
    transfer_flag=$(($transfer_flag + $return_value))

    # Check that all files were copied successfully. If any transfers failed, leave file in 
    # directory so tranfer can be attempted the next time the script runs
    if [[ "${transfer_flag}" -eq 0 ]]; then
        printf "File distribution successful: ${file}\n" | tee --append $SUMMARY_FILE

        # Move file to campus NAS for long term storage
        year=$(echo ${file_name} | cut --characters 1-4)
        month=$(echo ${file_name} | cut --characters 5-6)
        nas_site_dir="${NAS_DIR}/${RADAR_ID}_rawacf_dmap/${year}/${month}/"
        mkdir --parents $nas_site_dir
        mv --verbose $file $nas_site_dir
    else
        printf "File distribution failed: ${file}\n" | tee --append $SUMMARY_FILE
        # Leave failed transfer files in directory
    fi
done


# Distribute array files
borealis_files=$(find ${SOURCE} -maxdepth 1 -name "*rawacf.h*5")

# Iterate over all array files and back them up to NAS
if [[ -n $borealis_files ]]; then
    printf "\nDistributing the following HDF5 files:\n"
    printf '%s\n' "${borealis_files[@]}"
else
    printf "\nNo HDF5 files found to be distributed.\n" | tee --append $SUMMARY_FILE
fi

for file in $borealis_files; do
    printf "\n"
    h5stat $file >& /dev/null
    if [[ $? -ne 0 ]]; then
        printf "HDF5 file failed h5stat test: ${file}\n" | tee --append $SUMMARY_FILE
        mv --verbose $file $PROBLEM_FILES_DEST
    else
        printf "Distributing ${file}\n"
        chmod --verbose 644 "${file}"   # Change permissions to -rw-r--r--

        file_name=$(basename $file)

        year=$(echo ${file_name} | cut --characters 1-4)
        month=$(echo ${file_name} | cut --characters 5-6)
        nas_site_dir="${NAS_DIR}/${RADAR_ID}_rawacf/${year}/${month}/"
        mkdir --parents $nas_site_dir
        mv --verbose $file $nas_site_dir
        printf "File distribution successful: ${file}\n" | tee --append $SUMMARY_FILE
    fi
done

printf "\nFinished $(basename $0). End time: $(date --utc "+%Y%m%d %H:%M:%S UTC")\n\n" | tee --append $SUMMARY_FILE

# Sync summary log file with telemetry
printf "Syncing $(basename $SUMMARY_FILE) to $TELEMETRY:$TELEMETRY_SCRIPT_DIR\n\n"
rsync --archive --rsh="$TELEMETRY_RSH" $SUMMARY_FILE $TELEMETRY:$TELEMETRY_SCRIPT_DIR

exit
