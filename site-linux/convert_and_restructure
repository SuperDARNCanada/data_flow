#!/bin/bash
# Copyright 2019 SuperDARN Canada, University of Saskatchewan
# Author: Marci Detwiller, Theodore Kolkman
#
# A script that uses pydarnio to convert Borealis files to SuperDARN DMap files. If
# $RADAR_ID is specified in CONVERT_ON_CAMPUS_SITES in config.sh, then no DMAP conversion is done.
# Backs up the source rawacf files before it begins. This script is to be run on
# the Site-Linux computer.
#
# To modify this script to operate on files stored on the Site-Linux computer instead of the NAS:
#	1. Remove RADAR_ID for the specified site from NAS_SITES in config.sh
#
# Dependencies:
#	- pydarnio installed in a virtualenv at $HOME/pydarnio-env
# 	- RADAR_ID and SLACK_DATAFLOW_WEBHOOK set as environment variables in $HOME/.profile
#	- ssh link established between Site-Linux and TELEMETRY computers
#
# This script should be run via an inotify daemon that triggers when the previous data flow script
# finishes executing

###################################################################################################

source "${HOME}/.profile"	# Load in environment variables
source "${HOME}/data_flow/config.sh"  # Load common data flow variables
source "${HOME}/data_flow/library/data_flow_functions.sh" # Load in function library
source "${HOME}/pydarnio-env/bin/activate"

###################################################################################################

# Define directories
if [[ " ${NAS_SITES[*]} " =~ " ${RADAR_ID} " ]]; then
	readonly DATA_DIR="/borealis_nfs/borealis_data" # On NAS
else
	readonly DATA_DIR="/data/borealis_data" # On Site Linux
fi
readonly SOURCE="${DATA_DIR}/daily" # this is the source
readonly ANTENNAS_IQ_DEST="${DATA_DIR}/antennas_iq_array"
readonly RAWACF_DMAP_DEST="${DATA_DIR}/rawacf_dmap"
readonly RAWACF_ARRAY_DEST="${DATA_DIR}/rawacf_array"
readonly BACKUP_DEST="${DATA_DIR}/backup"

# Create log file. New file created daily
readonly LOGGING_DIR="${HOME}/logs/convert_and_restructure/$(date +%Y/%m)"
mkdir --parents $LOGGING_DIR
readonly LOGFILE="${LOGGING_DIR}/$(date +%Y%m%d).convert_and_restructure.log"
readonly  SUMMARY_DIR="${HOME}/logs/convert_and_restructure/summary/$(date +%Y/%m)"
mkdir --parents $SUMMARY_DIR
readonly SUMMARY_FILE="${SUMMARY_DIR}/$(date -u +%Y%m%d).convert_and_restructure_summary.log"

# Telemetry directory for this script and site
readonly TELEMETRY_SCRIPT_DIR="${TELEMETRY_DIR}/${RADAR_ID}/convert_and_restructure"

###################################################################################################

# Ensure that only a single instance of this script runs.
if pidof -o %PPID -x -- "$(basename -- $0)" > /dev/null; then
	printf "Error: Script $0 is already running. Exiting...\n"
	exit 1
fi

exec &>> $LOGFILE # Redirect STDOUT and STDERR to $LOGFILE

printf "################################################################################\n\n" | tee --append $SUMMARY_FILE

printf "Executing $0 on $(hostname) for ${RADAR_ID}\n" | tee --append $SUMMARY_FILE
date --utc "+%Y%m%d %H:%M:%S UTC" | tee --append $SUMMARY_FILE

# Get status info on data_flow and pyDARNio repos
printf "data_flow: $(git -C ${HOME}/data_flow status | grep "On branch"), last commit: \
		$(git -C ${HOME}/data_flow log -1 --format="%h %cd" --date=iso)\n" | tee --append $SUMMARY_FILE
printf "pyDARNio: $(git -C ${HOME}/pyDARNio status | grep "On branch"), last commit: \
		$(git -C ${HOME}/pyDARNio log -1 --format="%h %cd" --date=iso)\n" | tee --append $SUMMARY_FILE

printf "Conversion directory: $DATA_DIR\n\n" | tee --append $SUMMARY_FILE

# Find files to be converted
ANTENNAS_IQ_FILES=$(find "${SOURCE}" -name "*antennas_iq.h5" -type f)
RAWACF_CONVERT_FILES=$(find "${SOURCE}" -name "*rawacf.h5" -type f)
RAWACF_DMAP_FILES=$(find "${SOURCE}" -name "*.rawacf" -type f)

# Copy the source rawacf file to backup.
if [[ -n $ANTENNAS_IQ_FILES ]]; then
    printf "Moving antennas_iq hdf5 files\n"
    mv --verbose $ANTENNAS_IQ_FILES $ANTENNAS_IQ_DEST
fi

# Copy the source rawacf file to backup.
if [[ -n $RAWACF_CONVERT_FILES ]]; then
    printf "Backing up rawacf hdf5 files\n"
    cp --verbose --preserve $RAWACF_CONVERT_FILES $BACKUP_DEST
    mv --verbose $RAWACF_CONVERT_FILES $RAWACF_ARRAY_DEST
fi

printf "\n\n"
# Transfer rawacf dmap files to campus
for f in $RAWACF_DMAP_FILES; do
    if [[ " ${RAWACF_SITES[*]} " =~ " ${RADAR_ID} " ]]; then
        printf "\nHandling ${f}\n"

        # Ensure the permissions are read/write/execute for the group
        chmod --verbose 775 $f

        # Back up the file first, just as for HDF5 files
        cp --verbose --preserve $f $BACKUP_DEST

        # Move the file so the rsync_to_campus script will pick it up
        mv --verbose $f $RAWACF_DMAP_DEST

    else
        printf "Not transferring: ${f}\n" | tee --append $SUMMARY_FILE
        # File is already backed up, so we can remove it from this directory
        rm --verbose $f
    fi
done

printf "\nFinished $(basename $0). End time: $(date --utc "+%Y%m%d %H:%M:%S UTC")\n\n" | tee --append $SUMMARY_FILE

# Sync summary log file with campus
printf "Syncing $(basename $SUMMARY_FILE) to $TELEMETRY:$TELEMETRY_SCRIPT_DIR\n\n"
rsync --archive --rsh="$TELEMETRY_RSH" $SUMMARY_FILE $TELEMETRY:$TELEMETRY_SCRIPT_DIR

exit