#!/bin/bash
# Copyright 2019 SuperDARN Canada, University of Saskatchewan
# Author: Marci Detwiller
#
# Last Edited: October 2022 by Theo Kolkman
# Refactored for inotify usage
#
# A script that uses pydarnio to convert Borealis files to SuperDARN DMap files as well as 
# restructures the hdf5 files to be multidimensional arrays for better file readability. Backs up 
# the source site files before it begins. This script is to be run on the Site-Linux computer.
#
# To modify this script to operate on files stored on the Site-Linux computer instead of the NAS:
#	1. Remove RADARID for the specified site from NAS_SITES in config.sh
#
# Dependencies:
#	- pydarnio installed in a virtualenv at $HOME/pydarnio-env
# 	- RADARNAME and RADARID set as environment variables in $HOME/.bashrc
#	- ssh link established between Site-Linux and TELEMETRY computers
#
# This script should be run via an inotify daemon that triggers when the previous data flow script
# finishes executing

###################################################################################################

source "${HOME}/.bashrc"    # source the RADARID, SDCOPY and other things
source "${HOME}/data_flow/config.sh"  # Load common data flow variables
source "${HOME}/data_flow/library/data_flow_functions.sh" # Load in function library
source "${HOME}/pydarnio-env/bin/activate"

###################################################################################################

# Define directories
if [[ " ${NAS_SITES[*]} " =~ " ${RADARID} " ]]; then
	readonly DATA_DIR="/borealis_nfs/borealis_data" # On NAS
else
	readonly DATA_DIR="/data/borealis_data" # On Site Linux
fi
readonly SOURCE="${DATA_DIR}/daily" # this is the source
readonly RAWACF_DMAP_DEST="${DATA_DIR}/rawacf_dmap"
readonly RAWACF_ARRAY_DEST="${DATA_DIR}/rawacf_array"
readonly BFIQ_ARRAY_DEST="${DATA_DIR}/bfiq_array"
readonly ANTENNAS_IQ_ARRAY_DEST="${DATA_DIR}/antennas_iq_array"
readonly BACKUP_DEST="${DATA_DIR}/backup"
readonly PROBLEM_FILES_DEST="${DATA_DIR}/conversion_failure"

# Create log file. New file created daily
readonly LOGGING_DIR="${HOME}/logs/convert_and_restructure/$(date +%Y)/$(date +%m)"
mkdir --parents $LOGGING_DIR
readonly LOGFILE="${LOGGING_DIR}/$(date +%Y%m%d).convert_and_restructure.log"
readonly  SUMMARY_DIR="${HOME}/logs/convert_and_restructure/summary/$(date +%Y)/$(date +%m)"
mkdir --parents $SUMMARY_DIR
readonly SUMMARY_FILE="${SUMMARY_DIR}/$(date -u +%Y%m%d).convert_and_restructure_summary.log"

# Telemetry directory for this script and site
readonly TELEMETRY_SCRIPT_DIR="${TELEMETRY_DIR}/${RADARID}/convert_and_restructure"

###################################################################################################

# Redirect all stdout and sterr in this script to $LOGFILE
exec &>> $LOGFILE # Redirect STDOUT and STDERR to $LOGFILE

printf "################################################################################\n\n" | tee --append $SUMMARY_FILE

printf "Executing $0 on $(hostname)\n" | tee --append $SUMMARY_FILE
date --utc "+%Y%m%d %H:%M:%S UTC" | tee --append $SUMMARY_FILE

# Ensure that only a single instance of this script runs.
if pidof -o %PPID -x -- "$(basename -- $0)" > /dev/null; then
	printf "Error: Script $0 is already running. Exiting...\n"
	exit 1
fi

# Get status info on data_flow and pyDARNio repos
printf "data_flow: $(git -C ${HOME}/data_flow status | grep "On branch"), last commit: \
		$(git -C ${HOME}/data_flow log -1 --format="%h %cd" --date=iso)\n" | tee --append $SUMMARY_FILE
printf "pyDARNio: $(git -C ${HOME}/pyDARNio status | grep "On branch"), last commit: \
		$(git -C ${HOME}/pyDARNio log -1 --format="%h %cd" --date=iso)\n" | tee --append $SUMMARY_FILE

printf "Conversion directory: $DATA_DIR\n\n" | tee --append $SUMMARY_FILE

# Find files to be converted
RAWACF_CONVERT_FILES=$(find "${SOURCE}" -name "*rawacf.hdf5.site" -type f)
BFIQ_CONVERT_FILES=$(find "${SOURCE}" -name "*bfiq.hdf5.site" -type f)
ANTENNAS_IQ_CONVERT_FILES=$(find "${SOURCE}" -name "*antennas_iq.hdf5.site" -type f)

# Copy the source rawacf file to backup.
if [[ -n $RAWACF_CONVERT_FILES ]]; then
    printf "Backing up rawacf .site files\n"
    cp --verbose --preserve $RAWACF_CONVERT_FILES $BACKUP_DEST
fi
if [[ -n $BFIQ_CONVERT_FILES ]]; then
    printf "Backing up bfiq .site files\n"
    cp --verbose --preserve $BFIQ_CONVERT_FILES $BACKUP_DEST
fi


printf "\n\n"
if [[ -n $RAWACF_CONVERT_FILES ]]; then
	printf "Converting the following rawacf files:\n"
	printf '%s\n' "${RAWACF_CONVERT_FILES[@]}"
else
	printf "No rawacf files found to be converted.\n" | tee --append $SUMMARY_FILE
fi

# Convert rawacf files to array and dmap format
for f in $RAWACF_CONVERT_FILES; do
    if [[ " ${RAWACF_SITES[*]} " =~ " ${RADARID} " ]]; then
        printf "\nConverting ${f}\n"
        printf "python3 remove_record.py $(basename ${f})\n"
        output=$(python3 ${HOME}/data_flow/site-linux/remove_record.py ${f})
        if [[ -n "$output" ]]; then
            printf "Removed records from ${f}:\n${remove_records_output}\n" | tee --append $SUMMARY_FILE
        fi

        # Don't produce dmap files if only array files are transferred to campus
        if [[ " ${LOW_BANDWIDTH_SITES[*]} " =~ " ${RADARID} " ]]; then
            printf "python3 borealis_convert_file.py $(basename ${f})\n"
            python3 "${HOME}/data_flow/site-linux/borealis_convert_file.py" $f
        else
            printf "python3 borealis_convert_file.py --dmap $(basename ${f})\n"
            python3 "${HOME}/data_flow/site-linux/borealis_convert_file.py" --dmap $f
        fi

        ret=$?
        if [[ $ret -eq 0 ]]; then
            # move the resulting files if all was successful then remove the source site file.

            if [[ ! " ${LOW_BANDWIDTH_SITES[*]} " =~ " ${RADARID} " ]]; then
                dmap_file_start="${f%.rawacf.hdf5.site}"

                # remove last character(s) (slice_id)
                slice_id="${dmap_file_start##*.}"
                dmap_file_wo_slice_id="${dmap_file_start%${slice_id}}"

                ordinal_id="$(($slice_id + 97))"
                file_character=$(chr $ordinal_id)
                dmap_file="${dmap_file_wo_slice_id}${file_character}.rawacf.bz2"
                mv --verbose $dmap_file $RAWACF_DMAP_DEST
            fi

            array_file="${f%.site}"
            mv --verbose $array_file $RAWACF_ARRAY_DEST
            rm --verbose $f
            printf "Successfully converted: ${f}\n" | tee --append $SUMMARY_FILE
        else
            printf "File failed to convert: ${f}\n" | tee --append $SUMMARY_FILE
            mv --verbose $f $PROBLEM_FILES_DEST
        fi
    else
        printf "Not converting: ${f}\n" | tee --append $SUMMARY_FILE
        mv --verbose $f $RAWACF_ARRAY_DEST
    fi
done


printf "\n\n"
if [[ -n $BFIQ_CONVERT_FILES ]]; then
	printf "Converting the following bfiq files:\n"
	printf '%s\n' "${BFIQ_CONVERT_FILES[@]}"
else
	printf "No bfiq files found to be converted.\n" | tee --append $SUMMARY_FILE
fi

# Convert bfiq files to array format
for f in $BFIQ_CONVERT_FILES; do
    if [[ " ${BFIQ_SITES[*]} " =~ " ${RADARID} " ]]; then
        printf "\nConverting ${f}\n"
        printf "python3 remove_record.py $(basename ${f})\n"
        output=$(python3 ${HOME}/data_flow/site-linux/remove_record.py ${f})
        if [[ -n "$output" ]]; then
            printf "Removed records from ${f}:\n${remove_records_output}\n" | tee --append $SUMMARY_FILE
        fi
        printf "python3 borealis_convert_file.py $(basename ${f})\n"
        python3 "${HOME}/data_flow/site-linux/borealis_convert_file.py" $f
        ret=$?
        if [[ $ret -eq 0 ]]; then
            # Only converting array file
            array_file="${f%.site}"
            mv --verbose $array_file $BFIQ_ARRAY_DEST
            rm --verbose $f
            printf "Successfully converted: ${f}\n" | tee --append $SUMMARY_FILE
        else
            printf "File failed to convert: ${f}\n" | tee --append $SUMMARY_FILE
            mv --verbose $f $PROBLEM_FILES_DEST
        fi
    else
        printf "Not converting: ${f}\n" | tee --append $SUMMARY_FILE
        mv --verbose $f $BFIQ_ARRAY_DEST
    fi
done


printf "\n\n"
if [[ -n $ANTENNAS_IQ_CONVERT_FILES ]]; then
	printf "Converting the following antennas_iq files:\n"
	printf '%s\n' "${ANTENNAS_IQ_CONVERT_FILES[@]}"
else
	printf "No antennas_iq files found to be converted.\n" | tee --append $SUMMARY_FILE
fi

# Convert antennas_iq files to array format
for f in $ANTENNAS_IQ_CONVERT_FILES; do
    if [[ " ${ANTENNAS_IQ_SITES[*]} " =~ " ${RADARID} " ]]; then
        printf "\nConverting ${f}\n"
        printf "python3 remove_record.py $(basename ${f})\n"
        output=$(python3 ${HOME}/data_flow/site-linux/remove_record.py ${f})
        if [[ -n "$output" ]]; then
            printf "Removed records from ${f}:\n${remove_records_output}\n" | tee --append $SUMMARY_FILE
        fi

        # Use BorealisRestructure if site has low memory
        if [[ " ${LOW_MEMORY_SITES[*]} " =~ " ${RADARID} " ]]; then 
            printf "python3 borealis_convert_file.py --low_memory $(basename ${f})\n"
            python3 "${HOME}/data_flow/site-linux/borealis_convert_file.py" --low_memory $f
        else 
            printf "python3 borealis_convert_file.py $(basename ${f})\n"
            python3 "${HOME}/data_flow/site-linux/borealis_convert_file.py" $f
        fi
        ret=$?

        if [ $ret -eq 0 ]; then
            # then remove source site file.
            array_file="${f%.site}"
            mv --verbose $array_file $ANTENNAS_IQ_ARRAY_DEST
            rm --verbose $f
            printf "Successfully converted: ${f}\n" | tee --append $SUMMARY_FILE
        else
            printf "File failed to convert: ${f}\n" | tee --append $SUMMARY_FILE
            mv --verbose $f $PROBLEM_FILES_DEST
        fi
    else
        printf "Not converting: ${f}\n" | tee --append $SUMMARY_FILE
        mv --verbose $f  $ANTENNAS_IQ_ARRAY_DEST
    fi
done

printf "\nFinished $(basename $0). End time: $(date --utc "+%Y%m%d %H:%M:%S UTC")\n\n" | tee --append $SUMMARY_FILE

# Sync summary log file with campus
printf "Syncing $(basename $SUMMARY_FILE) to $TELEMETRY:$TELEMETRY_SCRIPT_DIR\n\n"
rsync --archive --rsh="$RSH" $SUMMARY_FILE $TELEMETRY:$TELEMETRY_SCRIPT_DIR

exit