#!/bin/bash
# Copyright 2019 SuperDARN Canada, University of Saskatchewan
# Author: Dieter Andre, Theodore Kolkman
#
# A singleton script to transfer rawacf dmap and hdf5 files from the NAS on site to sdc-serv on 
# campus. Files are copied first and removed once copy is confirmed to be successful. 
#
# To modify this script to transfer files from a local Site-Linux directory instead of the NAS:
#	  - Remove RADAR_ID for the specified site from NAS_SITES in config.sh
#
# Dependencies:
# - RADAR_ID and SDCOPY set as environment variables in ${HOME}/.profile
#	- ssh link established between Site-Linux and SDCOPY computers
#	- ssh link established between Site-Linux and TELEMETRY computers
# - ${HOME}/.ssh/controlmasters/ directory exists
# - ${HOME}/.ssh/config has the following ([xxxx] indicates you should fill this in intelligently):
# HOST [SDCOPY address, either IP or hostname]
#     User [SDCOPY username]
#     ControlPath ~/.ssh/controlmasters/%C
#     ControlMaster auto
#     ControlPersist 10m
#
# This script should be run via an inotify daemon triggering when the previous data flow script
# finishes execution

###################################################################################################

source "${HOME}/.profile"	# Load in environment variables
source "${HOME}/data_flow/config.sh"  # Load common data flow variables
source "${HOME}/data_flow/library/data_flow_functions.sh" # Load dataflow functions

###################################################################################################

# Location all files will be transferring from
if [[ " ${NAS_SITES[*]} " =~ " ${RADAR_ID} " ]]; then
	readonly DATA_DIR="/borealis_nfs/borealis_data" # On NAS
else
	readonly DATA_DIR="/data/borealis_data" # On Site Linux
fi
readonly DMAP_SOURCE="${DATA_DIR}/rawacf_dmap/"
readonly HDF5_SOURCE="${DATA_DIR}/rawacf_array/"
readonly PLOT_SOURCE="${HOME}/logs/daily_plots/"

# If site isn't transferring dmap files, send to holding directory for campus conversion
readonly HDF5_DEST="/sddata/${RADAR_ID}_holding_dir"
readonly DMAP_DEST="/sddata/${RADAR_ID}_data/"
readonly PLOT_DEST="/sddata/antennas_iq_plots/${RADAR_ID}_iq_plots/"

# Create log file. New file created daily
readonly LOGGING_DIR="${HOME}/logs/rsync_to_campus/$(date +%Y/%m)"
mkdir --parents $LOGGING_DIR
readonly LOGFILE="${LOGGING_DIR}/$(date +%Y%m%d).rsync_to_campus.log"
readonly SUMMARY_DIR="${HOME}/logs/rsync_to_campus/summary/$(date +%Y/%m)"
mkdir --parents $SUMMARY_DIR
readonly SUMMARY_FILE="${SUMMARY_DIR}/$(date -u +%Y%m%d).rsync_to_campus_summary.log"

# Telemetry directory for this script and site
readonly TELEMETRY_SCRIPT_DIR="${TELEMETRY_DIR}/${RADAR_ID}/rsync_to_campus"

###################################################################################################

# Ensure that only a single instance of this script runs.
if pidof -o %PPID -x -- "$(basename -- $0)" > /dev/null; then
	printf "Error: Script $0 is already running. Exiting...\n"
	exit 1
fi

exec &>> $LOGFILE # Redirect STDOUT and STDERR to $LOGFILE

printf "################################################################################\n\n" | tee --append $SUMMARY_FILE

# Date in UTC format for logging
printf "Executing $0 on $(hostname) for ${RADAR_ID}\n" | tee --append $SUMMARY_FILE
date --utc "+%Y%m%d %H:%M:%S UTC" | tee --append $SUMMARY_FILE

# Get status info on data_flow repo
printf "data_flow: $(git -C ${HOME}/data_flow status | grep "On branch"), last commit: \
		$(git -C ${HOME}/data_flow log -1 --format="%h %cd" --date=iso)\n" | tee --append $SUMMARY_FILE

printf "Transferring from: $DATA_DIR\n" | tee --append $SUMMARY_FILE
printf "Transferring HDF5 files to: $SDCOPY:$HDF5_DEST\n\n" | tee --append $SUMMARY_FILE
printf "Transferring DMap files to: $SDCOPY:$DMAP_DEST\n\n" | tee --append $SUMMARY_FILE


# Establish multiplexed SSH connection for all rsync's to $SDCOPY
# -N: do not execute a remote command on ${SDCOPY}
# -f: run in the background
ssh -N -f ${SDCOPY}

# Verify the multiplexed session is running
ssh -O check ${SDCOPY}
return_value=$?
if [[ $? -ne 0 ]]; then
    printf "Could not establish connection to ${SDCOPY}\n" | tee --append $SUMMARY_FILE
    printf "Exiting...\n"
    exit
fi

# Find all dmap files to transfer
files=$(find ${DMAP_SOURCE} -name '*rawacf.bz2' -printf '%p\n')

if [[ -n $files ]]; then
	printf "\nPlacing following dmap files in ${SDCOPY}:${DMAP_DEST}:\n"
	printf '%s\n' "${files[@]}"
else
	printf "No dmap files found to be transferred.\n" | tee --append $SUMMARY_FILE
fi

# Transfer all files found
for file in $files; do
	printf "\nTransferring: ${file} to ${SDCOPY}:${DMAP_DEST}\n"
	rsync -av --append-verify --timeout=180 --rsh=ssh $file $SDCOPY:$DMAP_DEST

	# Check if transfer was okay using the md5sum program, then remove the file if it matches
	verify_transfer $file "${DMAP_DEST}/$(basename $file)" $SDCOPY
	return_value=$?
	if [[ $return_value -eq 0 ]]; then
		printf "Successfully transferred: ${file}\n" | tee --append $SUMMARY_FILE
		printf "Deleting file...\n"
		rm --verbose $file
	else
			# If file not transferred successfully, don't delete and try again next time
		printf "Transfer failed: ${file}\n" | tee --append $SUMMARY_FILE
		printf "File not deleted.\n"
	fi
done


# Find all hdf5 files to transfer
files=$(find ${HDF5_SOURCE} -name '*rawacf.h5' -printf '%p\n')

if [[ -n $files ]]; then
	printf "\n\nPlacing following hdf5 files in ${SDCOPY}:${HDF5_DEST}:\n"
	printf '%s\n' "${files[@]}"
else
	printf "\nNo hdf5 files found to be transferred.\n" | tee --append $SUMMARY_FILE
fi

# Transfer all files found
for file in $files; do
	printf "\nTransferring: $(basename $file)\n"
	rsync -av --append-verify --timeout=180 --rsh=ssh $file $SDCOPY:$HDF5_DEST

	# Check if transfer was okay using the md5sum program
	verify_transfer $file "${HDF5_DEST}/$(basename $file)" $SDCOPY
	return_value=$?
	if [[ $return_value -eq 0 ]]; then
		printf "Successfully transferred: ${file}\n" | tee --append $SUMMARY_FILE
		printf "Deleting file...\n"
		rm --verbose $file
	else
		# If file not transferred successfully, don't delete and try again next time
		printf "Transfer failed: ${file}\n" | tee --append $SUMMARY_FILE
		printf "File not deleted.\n"
	fi
done


# Find all antennas_iq plots to transfer
files=$(find "${PLOT_SOURCE}" -type f -regex ".*\.\(png\|jpg\)")

if [[ -n $files ]]; then
	printf "\n\nPlacing the following antenna iq plots in ${SDCOPY}:${PLOT_DEST}:\n"
	printf '%s\n' "${files[@]}"
else
	printf "\nNo antennas iq plots found to be transferred.\n" | tee --append $SUMMARY_FILE
fi

for file in $files; do
	printf "\nTransferring: ${file}\n"
	rsync -av --append-verify --timeout=180 --rsh=ssh ${file} $SDCOPY:$PLOT_DEST

	# Check if transfer was okay using the md5sum program
	verify_transfer $file "${PLOT_DEST}/$(basename $file)" $SDCOPY
	return_value=$?
	if [[ $return_value -eq 0 ]]; then
		printf "Successfully transferred: ${file}\n" | tee --append $SUMMARY_FILE
		printf "Deleting file...\n"
		rm --verbose ${file}
	else
		# If file not transferred successfully, try again next time, don't delete
		printf "Transfer failed: ${file}\n" | tee --append $SUMMARY_FILE
		printf "File not deleted.\n"
	fi
done

printf "\nFinished $(basename $0). End time: $(date --utc "+%Y%m%d %H:%M:%S UTC")\n\n" | tee --append $SUMMARY_FILE

# Sync summary log file with campus
printf "Syncing $(basename $SUMMARY_FILE) to $TELEMETRY:$TELEMETRY_SCRIPT_DIR\n\n"
rsync --archive --rsh="$TELEMETRY_RSH" $SUMMARY_FILE $TELEMETRY:$TELEMETRY_SCRIPT_DIR

# Close the multiplexed SSH session
ssh -O exit ${SDCOPY} <&-

exit
